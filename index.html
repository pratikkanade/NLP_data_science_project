
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>CO₂ Data Pipeline - Fetch, Store, Process in Snowflake</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/claat-public/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="co2-data-pipeline"
                  title="CO₂ Data Pipeline - Fetch, Store, Process in Snowflake"
                  environment="web"
                  feedback-link="https://your-feedback-link.com">
    
      <google-codelab-step label="📌 Table of Contents" duration="0">
        <ol type="1">
<li><a href="#prerequisites" target="_blank">Prerequisites</a></li>
<li><a href="#fetching-co%E2%82%82-data" target="_blank">Fetching CO₂ Data</a></li>
<li><a href="#uploading-data-to-aws-s3" target="_blank">Uploading Data to AWS S3</a></li>
<li><a href="#loading-data-into-snowflake" target="_blank">Loading Data into Snowflake</a></li>
<li><a href="#transforming-and-normalizing-data" target="_blank">Transforming &amp; Normalizing Data</a></li>
<li><a href="#analytics-and-reporting" target="_blank">Analytics &amp; Reporting</a></li>
<li><a href="#automating-updates" target="_blank">Automating Updates</a></li>
<li><a href="#using-jinja-for-sql-templating" target="_blank">Using Jinja for SQL Templating</a></li>
<li><a href="#deployment-with-github-actions" target="_blank">Deployment with GitHub Actions</a></li>
<li><a href="#conclusion" target="_blank">Conclusion</a></li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="1️⃣ Prerequisites" duration="0">
        <p>Before starting, ensure you have:</p>
<ul>
<li><strong>Python 3.x installed</strong></li>
<li><strong>AWS S3 credentials set up</strong></li>
<li><strong>A Snowflake account with schema permissions</strong></li>
<li><strong>Installed Python libraries</strong> (<code>boto3</code>, <code>snowflake-connector-python</code>, etc.)</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="2️⃣ Fetching CO₂ Data" duration="0">
        <p>We fetch <strong>daily CO₂ readings</strong> from <strong>NOAA&#39;s data portal</strong>.</p>
<pre><code language="language-python" class="language-python">import requests

URL = &#34;https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_daily_mlo.txt&#34;
response = requests.get(URL)

# Save as CSV
with open(&#34;co2_data.csv&#34;, &#34;w&#34;) as f:
    f.write(response.text)

print(&#34;✅ CO₂ Data Fetched Successfully&#34;)
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="3️⃣ Uploading Data to AWS S3" duration="0">
        <p>Once fetched, the data is stored in an AWS S3 bucket.</p>
<pre><code language="language-python" class="language-python">import boto3

s3 = boto3.client(&#39;s3&#39;)
bucket_name = &#34;big.data.ass3&#34;

s3.upload_file(&#34;co2_data.csv&#34;, bucket_name, &#34;raw_data/co2_data.csv&#34;)

print(&#34;✅ CO₂ Data Uploaded to S3&#34;)
</code></pre>
<p>To verify:</p>
<pre><code language="language-bash" class="language-bash">aws s3 ls s3://big.data.ass3/raw_data/
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="4️⃣ Loading Data into Snowflake" duration="0">
        <h2 is-upgraded>Storage Integration</h2>
<p>We first set up Snowflake Storage Integration for AWS S3.</p>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE STORAGE INTEGRATION CO2_S3_INTEGRATION
TYPE = EXTERNAL_STAGE
STORAGE_PROVIDER = &#39;S3&#39;
STORAGE_AWS_ROLE_ARN = &#39;arn:aws:iam::183295451617:role/MySnowflakeRole&#39;
ENABLED = TRUE
STORAGE_ALLOWED_LOCATIONS = (&#39;s3://big.data.ass3/&#39;);
</code></pre>
<h2 is-upgraded>Defining Snowflake Stage &amp; File Format</h2>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE STAGE CO2_STAGE
STORAGE_INTEGRATION = CO2_S3_INTEGRATION
URL = &#39;s3://big.data.ass3/&#39;;

CREATE OR REPLACE FILE FORMAT CO2_CSV_FORMAT
TYPE = CSV
FIELD_DELIMITER = &#39;,&#39;
SKIP_HEADER = 1;
</code></pre>
<h2 is-upgraded>Loading Data from S3 into Snowflake</h2>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE TABLE RAW_DOW30_STAGING (
    YEAR INT,
    MONTH INT,
    DAY INT,
    DECIMAL_DATE FLOAT,
    CO2_EMISSION FLOAT
);

COPY INTO RAW_DOW30_STAGING
FROM @CO2_STAGE/raw_data/co2_data.csv
FILE_FORMAT = (FORMAT_NAME = &#39;CO2_CSV_FORMAT&#39;)
FORCE = TRUE;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="5️⃣ Transforming &amp; Normalizing Data" duration="0">
        <h2 is-upgraded>Harmonizing CO₂ Data</h2>
<p>We store harmonized data in the PUBLIC schema.</p>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE TABLE DOW30_HARMONIZED AS
SELECT YEAR, MONTH, DAY, DECIMAL_DATE, CO2_EMISSION FROM RAW_DOW30_STAGING;
</code></pre>
<h2 is-upgraded>Normalizing CO₂ Emissions</h2>
<p>We add a normalized CO₂ column and compute values.</p>
<pre><code language="language-sql" class="language-sql">ALTER TABLE DOW30_HARMONIZED ADD COLUMN NORMALIZED_CO2 FLOAT;
UPDATE DOW30_HARMONIZED
SET NORMALIZED_CO2 = CO2_EMISSION / 400.0;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="6️⃣ Analytics &amp; Reporting" duration="0">
        <p>We create an analytics table in <code>ANALYTICS_DOW30</code> to compute monthly CO₂ statistics.</p>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE TABLE ANALYTICS_DOW30 AS
SELECT 
    YEAR, 
    MONTH, 
    AVG(CO2_EMISSION) AS AVG_CO2, 
    MAX(CO2_EMISSION) AS MAX_CO2, 
    MIN(CO2_EMISSION) AS MIN_CO2
FROM DOW30_HARMONIZED
GROUP BY YEAR, MONTH;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="7️⃣ Automating Updates" duration="0">
        <p>To keep the dataset up-to-date, we automate merging new data.</p>
<h2 is-upgraded>Stored Procedure for Updates</h2>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE PROCEDURE UPDATE_CO2_PROCEDURE()
RETURNS STRING
LANGUAGE SQL
AS 
$$
BEGIN
    MERGE INTO DOW30_HARMONIZED AS TARGET
    USING (SELECT * FROM RAW_DOW30_STAGING) AS SOURCE
    ON TARGET.YEAR = SOURCE.YEAR AND TARGET.MONTH = SOURCE.MONTH AND TARGET.DAY = SOURCE.DAY
    WHEN MATCHED THEN 
        UPDATE SET TARGET.CO2_EMISSION = SOURCE.CO2_EMISSION
    WHEN NOT MATCHED THEN 
        INSERT (YEAR, MONTH, DAY, DECIMAL_DATE, CO2_EMISSION) 
        VALUES (SOURCE.YEAR, SOURCE.MONTH, SOURCE.DAY, SOURCE.DECIMAL_DATE, SOURCE.CO2_EMISSION);
    
    RETURN &#39;Update Successful!&#39;;
END;
$$;
</code></pre>
<h2 is-upgraded>Scheduled Task for Daily Updates</h2>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE TASK UPDATE_CO2_DATA
SCHEDULE = &#39;USING CRON 0 8 * * * UTC&#39;
AS 
CALL UPDATE_CO2_PROCEDURE();

ALTER TASK UPDATE_CO2_DATA RESUME;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="8️⃣ Using Jinja for SQL Templating" duration="0">
        <p>Jinja helps create dynamic SQL queries with placeholders for variables.</p>
<h2 is-upgraded>Example Jinja Template (<code>templates/load_data.sql.jinja</code>)</h2>
<pre><code language="language-sql" class="language-sql">COPY INTO &#123;&#123; table_name }}
FROM @&#123;&#123; stage_name }}/&#123;&#123; file_path }}
FILE_FORMAT = (FORMAT_NAME = &#39;&#123;&#123; file_format }}&#39;)
FORCE = TRUE;
</code></pre>
<h2 is-upgraded>Using Jinja in Python</h2>
<pre><code language="language-python" class="language-python">from jinja2 import Environment, FileSystemLoader

env = Environment(loader=FileSystemLoader(&#34;templates&#34;))
template = env.get_template(&#34;load_data.sql.jinja&#34;)

sql_query = template.render(
    table_name=&#34;RAW_DOW30_STAGING&#34;,
    stage_name=&#34;CO2_STAGE&#34;,
    file_path=&#34;raw_data/co2_data.csv&#34;,
    file_format=&#34;CO2_CSV_FORMAT&#34;
)

print(sql_query)
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="9️⃣ Deployment with GitHub Actions" duration="0">
        <p>We use GitHub Actions to automate pipeline execution.</p>
<h2 is-upgraded><code>.github/workflows/snowflake_ci.yml</code></h2>
<pre><code language="language-yaml" class="language-yaml">name: Snowflake CI Pipeline
on:
  push:
    branches: [ main ]
jobs:
  snowflake_ci:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
      - name: Install Dependencies
        run: |
          pip install snowflake-connector-python boto3 requests pandas &#34;pyarrow&lt;19.0.0&#34;
      - name: Run Snowflake Pipeline
        run: python &#34;co2_data_weather_data_pipeline/sql/snowflake_pipeline_1.py&#34;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="🔟🎯 Conclusion" duration="0">
        <p>In this guide, we:<br> ✅ Fetched CO₂ data from NOAA<br> ✅ Stored it in AWS S3<br> ✅ Loaded &amp; processed it in Snowflake<br> ✅ Built analytics reports<br> ✅ Automated data updates<br> ✅ Deployed via GitHub Actions</p>
<p>📌 Repository: [<a href="https://github.com/hishitathakkar/BigData_assignment3" target="_blank">GitHub Link</a>]<br> 📌 Author: Hishita Thakkar.</p>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/claat-public/native-shim.js"></script>
  <script src="https://storage.googleapis.com/claat-public/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/claat-public/prettify.js"></script>
  <script src="https://storage.googleapis.com/claat-public/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>

</body>
</html>
